
deepseek r1微调模型应用落地案例（医疗法律，PatientSeek），适合借鉴学习。
https://www.bilibili.com/video/BV17zAVevEtw/?spm_id_from=333.1387.upload.video_card.click&vd_source=5296b77bd88eec13d945adf9efc64874

https://medium.com/enterprise-rag/introducing-patientseek-the-first-open-source-med-legal-deepseek-reasoning-model-74f98e9608ae
https://huggingface.co/whyhow-ai/PatientSeek/tree/main/snapshots/70661aa9b9e6c69734b394916ddbc540fd4731bf

https://pan.quark.cn/s/ce195bd4aeeb#/list/share

如何使用PatientSeek
一、python sdk调用
安装python依赖

# cpu方式
pip install llama-cpp-python

# gpu
CMAKE_ARGS="-DGGML_CUDA=on" pip install llama-cpp-python

# 手动下载安装，先下载whl文件（地址：https://pan.quark.cn/s/c3c831672add）
(llama_cpp_python-0.3.4-cp312-cp312-linux_x86_64.whl)

# cpu
 pip install llama_cpp_python-0.3.4-cp312-cp312-linux_x86_64.whl

 # gpu
 CMAKE_ARGS="-DGGML_CUDA=on" pip install llama_cpp_python-0.3.4-cp312-cp312-linux_x86_64.whl
使用llama-cpp-python调用PatientSeek模型。格式兼容openai。

from llama_cpp import Llama

model_path = "/home/vr301/deepseek-models/patientSeek/DeepSeek-R1-Distill-Llama-8B-Q4_K_M.gguf"
llm = Llama(
    model_path=model_path,
    chat_format="llama-3"
)
# compatible with openai api
response = llm.create_chat_completion(
    messages=[
        {"role": "system", "content": "你是超强的助手"},
        {"role": "user", "content": "你是谁"}
    ]
)

print(response)
返回结果示例

{'id': 'chatcmpl-fbc9dd71-980c-4d11-a12f-187f035993eb', 'object': 'chat.completion', 'created': 1739679712, 'model': '/home/vr301/deepseek-models/patientSeek/DeepSeek-R1-Distill-Llama-8B-Q4_K_M.gguf', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '</think>\n\n您好！我是由中国的深度求索（DeepSeek）公司开发的智能助手DeepSeek-R1。如您有任何任何问题，我会尽我所能为您提供op'}], 'usage': {'prompt_tokens': 25, 'completion_tokens': 46, 'total_tokens': 71}}
二、ollama
下载gguf格式的文件 （如果huggingface无法连接，会提供一个下载地址链接：https://pan.quark.cn/s/1f829e97ac2d）

编写Modelfile文件，参考deepseek-r1蒸馏模型的写法

# Modelfile generated by "ollama show"
# To build a new Modelfile based on this, replace FROM with:
# FROM deepseek-r1:8b

FROM <you path to gguf file>
TEMPLATE """{{- if .System }}{{ .System }}{{ end }}
{{- range $i, $_ := .Messages }}
{{- $last := eq (len (slice $.Messages $i)) 1}}
{{- if eq .Role "user" }}<｜User｜>{{ .Content }}
{{- else if eq .Role "assistant" }}<｜Assistant｜>{{ .Content }}{{- if not $last }}<｜end▁of▁sentence｜>{{- end }}
{{- end }}
{{- if and $last (ne .Role "assistant") }}<｜Assistant｜>{{- end }}
{{- end }}"""
PARAMETER stop <｜begin▁of▁sentence｜>
PARAMETER stop <｜end▁of▁sentence｜>
PARAMETER stop <｜User｜>
PARAMETER stop <｜Assistant｜>
LICENSE """MIT License

Copyright (c) 2023 DeepSeek

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
"""

使用ollama创建模型

ollama create PatientSeek -f Modelfile
查看并运行模型

ollama list
ollama run PatientSeek