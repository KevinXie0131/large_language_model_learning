
https://huggingface.co/docs/hub/en/ollama

https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF
ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF
ollama run hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:Q4_K_M


https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/blob/main/Llama-3.2-3B-Instruct-f16.gguf
Modelfile:
FROM C:\Backup\QA\Llama-3.2-3B-Instruct-f16.gguf

ollama create --quantize q4_K_M mymodel
